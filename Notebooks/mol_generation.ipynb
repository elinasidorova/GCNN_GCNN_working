{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unique and valid fragments generated: 107308\n",
      "On generation 0/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cairne/miniconda3/envs/mol_torch_gcnn/lib/python3.10/site-packages/janus/janus.py:457: RuntimeWarning: overflow encountered in power\n",
      "  prob_ = 1.0 / (3.0 ** ((F_50_val - fitness) / (F_50_val - F_25_val)) + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    (Explr) Top Fitness: 15.811199999999957\n",
      "    (Explr) Top Smile: CCCCCCCCCCCCCCCCOP(=O)(O)Oc1ccc(C=Cc2ccc(OP(=O)(O)OCCCCCCCCCCCCCCCC)cc2)cc1\n",
      "    (Local) Top Fitness: 18.758599999999984\n",
      "    (Local) Top Smile: CCCCCCCCCCCCCCCCOOCc1cc(I)ccc1C=C(C=CP=O)C=Cc1ccc(OP(COO)OCCCCCCCCCCCCCCCC)cc1\n",
      "On generation 1/200\n",
      "    Training classifier neural net...\n",
      "No GPU available, defaulting to CPU.\n",
      "        Epoch:0 Loss:0.7787207961082458\n",
      "                Validation loss: 0.7838078141212463\n",
      "        Epoch:1000 Loss:0.13090628385543823\n",
      "                Validation loss: 0.13141220808029175\n",
      "        Early stopping at epoch: 985       loss: 0.13061510026454926\n",
      "    Obtaining Predictions\n",
      "No GPU available, defaulting to CPU.\n",
      "Number of batches:  109\n",
      "        Predicting Batch: 0/109\n",
      "        Predicting Batch: 1/109\n",
      "        Predicting Batch: 2/109\n",
      "        Predicting Batch: 3/109\n",
      "        Predicting Batch: 4/109\n",
      "        Predicting Batch: 5/109\n",
      "        Predicting Batch: 6/109\n",
      "        Predicting Batch: 7/109\n",
      "        Predicting Batch: 8/109\n",
      "        Predicting Batch: 9/109\n",
      "        Predicting Batch: 10/109\n",
      "        Predicting Batch: 11/109\n",
      "        Predicting Batch: 12/109\n",
      "        Predicting Batch: 13/109\n",
      "        Predicting Batch: 14/109\n",
      "        Predicting Batch: 15/109\n",
      "        Predicting Batch: 16/109\n",
      "        Predicting Batch: 17/109\n",
      "        Predicting Batch: 18/109\n",
      "        Predicting Batch: 19/109\n",
      "        Predicting Batch: 20/109\n",
      "        Predicting Batch: 21/109\n",
      "        Predicting Batch: 22/109\n",
      "        Predicting Batch: 23/109\n",
      "        Predicting Batch: 24/109\n",
      "        Predicting Batch: 25/109\n",
      "        Predicting Batch: 26/109\n",
      "        Predicting Batch: 27/109\n",
      "        Predicting Batch: 28/109\n",
      "        Predicting Batch: 29/109\n",
      "        Predicting Batch: 30/109\n",
      "        Predicting Batch: 31/109\n",
      "        Predicting Batch: 32/109\n",
      "        Predicting Batch: 33/109\n",
      "        Predicting Batch: 34/109\n",
      "        Predicting Batch: 35/109\n",
      "        Predicting Batch: 36/109\n",
      "        Predicting Batch: 37/109\n",
      "        Predicting Batch: 38/109\n",
      "        Predicting Batch: 39/109\n",
      "        Predicting Batch: 40/109\n",
      "        Predicting Batch: 41/109\n",
      "        Predicting Batch: 42/109\n",
      "        Predicting Batch: 43/109\n",
      "        Predicting Batch: 44/109\n",
      "        Predicting Batch: 45/109\n",
      "        Predicting Batch: 46/109\n",
      "        Predicting Batch: 47/109\n",
      "        Predicting Batch: 48/109\n",
      "        Predicting Batch: 49/109\n",
      "        Predicting Batch: 50/109\n",
      "        Predicting Batch: 51/109\n",
      "        Predicting Batch: 52/109\n",
      "        Predicting Batch: 53/109\n",
      "        Predicting Batch: 54/109\n",
      "        Predicting Batch: 55/109\n",
      "        Predicting Batch: 56/109\n",
      "        Predicting Batch: 57/109\n",
      "        Predicting Batch: 58/109\n",
      "        Predicting Batch: 59/109\n",
      "        Predicting Batch: 60/109\n",
      "        Predicting Batch: 61/109\n",
      "        Predicting Batch: 62/109\n",
      "        Predicting Batch: 63/109\n",
      "        Predicting Batch: 64/109\n",
      "        Predicting Batch: 65/109\n",
      "        Predicting Batch: 66/109\n",
      "        Predicting Batch: 67/109\n",
      "        Predicting Batch: 68/109\n",
      "        Predicting Batch: 69/109\n",
      "        Predicting Batch: 70/109\n",
      "        Predicting Batch: 71/109\n",
      "        Predicting Batch: 72/109\n",
      "        Predicting Batch: 73/109\n",
      "        Predicting Batch: 74/109\n",
      "        Predicting Batch: 75/109\n",
      "        Predicting Batch: 76/109\n",
      "        Predicting Batch: 77/109\n",
      "        Predicting Batch: 78/109\n",
      "        Predicting Batch: 79/109\n",
      "        Predicting Batch: 80/109\n",
      "        Predicting Batch: 81/109\n",
      "        Predicting Batch: 82/109\n",
      "        Predicting Batch: 83/109\n",
      "        Predicting Batch: 84/109\n",
      "        Predicting Batch: 85/109\n",
      "        Predicting Batch: 86/109\n",
      "        Predicting Batch: 87/109\n",
      "        Predicting Batch: 88/109\n",
      "        Predicting Batch: 89/109\n",
      "        Predicting Batch: 90/109\n",
      "        Predicting Batch: 91/109\n",
      "        Predicting Batch: 92/109\n",
      "        Predicting Batch: 93/109\n",
      "        Predicting Batch: 94/109\n",
      "        Predicting Batch: 95/109\n",
      "        Predicting Batch: 96/109\n",
      "        Predicting Batch: 97/109\n",
      "        Predicting Batch: 98/109\n",
      "        Predicting Batch: 99/109\n",
      "        Predicting Batch: 100/109\n",
      "        Predicting Batch: 101/109\n",
      "        Predicting Batch: 102/109\n",
      "        Predicting Batch: 103/109\n",
      "        Predicting Batch: 104/109\n",
      "        Predicting Batch: 105/109\n",
      "        Predicting Batch: 106/109\n",
      "        Predicting Batch: 107/109\n",
      "        Predicting Batch: 108/109\n",
      "    (Explr) Top Fitness: 18.758599999999984\n",
      "    (Explr) Top Smile: CCCCCCCCCCCCCCCCOOCc1cc(I)ccc1C=C(C=CP=O)C=Cc1ccc(OP(COO)OCCCCCCCCCCCCCCCC)cc1\n",
      "    (Local) Top Fitness: 19.928899999999995\n",
      "    (Local) Top Smile: CCCCCCCCCCCCCCCCCCCOOCc1cc(I)ccc1C=C(C=CP=O)C=Cc1ccc(OP(COO)OCCCCCCCCCCCCCCCC)cc1\n",
      "On generation 2/200\n",
      "    Training classifier neural net...\n",
      "No GPU available, defaulting to CPU.\n",
      "        Epoch:0 Loss:0.6446319818496704\n",
      "                Validation loss: 0.6330331563949585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from janus import JANUS, utils\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem, RDConfig, Descriptors\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "import torch\n",
    "import selfies\n",
    "\n",
    "def fitness_function(smi: str) -> float:\n",
    "    \"\"\" User-defined function that takes in individual smiles\n",
    "    and outputs a fitness value.\n",
    "    \"\"\"\n",
    "    # logP fitness\n",
    "    return Descriptors.MolLogP(Chem.MolFromSmiles(smi))\n",
    "\n",
    "def custom_filter(smi: str):\n",
    "    \"\"\" Function that takes in a smile and returns a boolean.\n",
    "    True indicates the smiles PASSES the filter.\n",
    "    \"\"\"\n",
    "    # smiles length filter\n",
    "    if len(smi) > 81 or len(smi) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "torch.multiprocessing.freeze_support()\n",
    "\n",
    "# all parameters to be set, below are defaults\n",
    "params_dict = {\n",
    "    # Number of iterations that JANUS runs for\n",
    "    \"generations\": 200,\n",
    "\n",
    "    # The number of molecules for which fitness calculations are done,\n",
    "    # exploration and exploitation each have their own population\n",
    "    \"generation_size\": 5000,\n",
    "\n",
    "    # Number of molecules that are exchanged between the exploration and exploitation\n",
    "    \"num_exchanges\": 5,\n",
    "\n",
    "    # Callable filtering function (None defaults to no filtering)\n",
    "    \"custom_filter\": custom_filter,\n",
    "\n",
    "    # Fragments from starting population used to extend alphabet for mutations\n",
    "    \"use_fragments\": True,\n",
    "\n",
    "    # An option to use a classifier as selection bias\n",
    "    \"use_classifier\": True,\n",
    "}\n",
    "\n",
    "# Set your SELFIES constraints (below used for manuscript)\n",
    "default_constraints = selfies.get_semantic_constraints()\n",
    "new_constraints = default_constraints\n",
    "new_constraints['S'] = 2\n",
    "new_constraints['P'] = 3\n",
    "selfies.set_semantic_constraints(new_constraints)  # update constraints\n",
    "\n",
    "# Create JANUS object.\n",
    "agent = JANUS(\n",
    "    work_dir = 'RESULTS',                                   # where the results are saved\n",
    "    fitness_function = fitness_function,                    # user-defined fitness for given smiles\n",
    "    start_population = \"../Data/sample_start_smiles.txt\",   # file with starting smiles population\n",
    "    **params_dict\n",
    ")\n",
    "\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}